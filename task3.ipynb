{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3.a Calculating Cohen's Kappa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading CSV files for Annotator1 and Annotator2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_annotator_1 = pd.read_csv('Annotator1.csv')\n",
    "df_annotator_2 = pd.read_csv('Annotator2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to extract words and their corresponding labels from the JSON format in 'label' column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_words_and_labels(label_json):\n",
    "    data = json.loads(label_json)\n",
    "    return [(item[\"text\"], item[\"labels\"][0]) for item in data] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a list of final data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data = []\n",
    "for _, row_1 in df_annotator_1.iterrows():\n",
    "    annotation_id = row_1[\"annotation_id\"]\n",
    "    \n",
    "    #extracting Annotator 1's words and labels\n",
    "    words_and_labels_1 = extract_words_and_labels(row_1[\"label\"])\n",
    "\n",
    "    #finding the corresponding row in Annotator 2's data\n",
    "    row_2 = df_annotator_2[df_annotator_2[\"annotation_id\"] == annotation_id].iloc[0]\n",
    "\n",
    "    #extracting Annotator 2's words and labels\n",
    "    words_and_labels_2 = extract_words_and_labels(row_2[\"label\"])\n",
    "\n",
    "    #combining the words and annotations from both annotators\n",
    "    for word_and_label_1, word_and_label_2 in zip(words_and_labels_1, words_and_labels_2):\n",
    "        word_1, label_1 = word_and_label_1\n",
    "        word_2, label_2 = word_and_label_2\n",
    "        final_data.append([annotation_id, word_1, label_1, label_2])\n",
    "    \n",
    "    df_final = pd.DataFrame(final_data, columns=[\"annotation_id\", \"word\", \"annotator_1_label\", \"annotator_2_label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   annotation_id    word annotator_1_label annotator_2_label\n",
      "0              1    कथित               ADJ               ADJ\n",
      "1              1   Delhi             PROPN             PROPN\n",
      "2              1  Liquor              NOUN              NOUN\n",
      "3              1    Scam              NOUN              NOUN\n",
      "4              1      पर               ADP               ADP\n"
     ]
    }
   ],
   "source": [
    "#printing the first 5 rows of final dataframe\n",
    "print(df_final.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     annotation_id  word annotator_1_label annotator_2_label\n",
      "341             20    से               ADP               ADV\n",
      "342             20  पूछे              VERB              VERB\n",
      "343             20  तीखे               ADJ               ADJ\n",
      "344             20  सवाल              NOUN              NOUN\n",
      "345             20     !                 X                 X\n"
     ]
    }
   ],
   "source": [
    "#printing the last 5 rows of final dataframe\n",
    "print(df_final.tail(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating Cohen's Kappa using the inbuilt function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cohen's Kappa: 0.7756229038108845\n"
     ]
    }
   ],
   "source": [
    "annotator_1_labels = df_final['annotator_1_label']\n",
    "annotator_2_labels = df_final['annotator_2_label']\n",
    "\n",
    "kappa_score = cohen_kappa_score(annotator_1_labels, annotator_2_labels)\n",
    "\n",
    "#printing the result\n",
    "print(f\"Cohen's Kappa: {kappa_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation for Cohen's Kappa\n",
    "\n",
    "The agreement score for NER Task is 0.7756229038108845 which seems like a decent agreement score. However, still some improvements can be made. The score is almost close to 0.8 which shows that there is a fairly good agreement between the annotators. The potential reasons for disagreement could be due to differences in interpretation of annotations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3.a Calculating Cohen's Kappa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating Fleiss's Kappa using inbuilt function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing Neccessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from statsmodels.stats.inter_rater import fleiss_kappa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating Fleiss' Kappa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fleiss' Kappa: 0.6662958843159064\n"
     ]
    }
   ],
   "source": [
    "file_annotator1 = 'Annotator1CV.csv'  \n",
    "file_annotator2 = 'Annotator2CV.csv'\n",
    "file_annotator3 = 'Annotator3CV.csv'\n",
    "\n",
    "#dataframes\n",
    "df1 = pd.read_csv(file_annotator1)\n",
    "df2 = pd.read_csv(file_annotator2)\n",
    "df3 = pd.read_csv(file_annotator3)\n",
    "\n",
    "df1 = df1[['annotation_id', 'choice']].rename(columns={'choice': 'Annotator1'})\n",
    "df2 = df2[['annotation_id', 'choice']].rename(columns={'choice': 'Annotator2'})\n",
    "df3 = df3[['annotation_id', 'choice']].rename(columns={'choice': 'Annotator3'})\n",
    "\n",
    "#merging the dataframes on annotation_id\n",
    "df_combined = df1.merge(df2, on='annotation_id').merge(df3, on='annotation_id')\n",
    "\n",
    "#creating a frequency matrix\n",
    "df_long = df_combined.melt(id_vars=['annotation_id'], value_vars=['Annotator1', 'Annotator2', 'Annotator3'],\n",
    "                           var_name='annotator', value_name='choice')\n",
    "\n",
    "#pivot to create a frequency matrix\n",
    "matrix = df_long.pivot_table(index='annotation_id', columns='choice', aggfunc='size', fill_value=0)\n",
    "\n",
    "#calculating Fleiss' Kappa\n",
    "kappa = fleiss_kappa(matrix.to_numpy(), method='fleiss')\n",
    "\n",
    "#printing the result\n",
    "print(f\"Fleiss' Kappa: {kappa}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation for Fleiss' Kappa\n",
    "\n",
    "The agreement score for Image Classification task is 0.6662958843159064. This shows a good enough agreement between the annotators. The discrepencies might be due to subjective interpretations."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
